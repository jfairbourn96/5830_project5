{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 5 Report\n",
    "\n",
    "## Team members: \n",
    "\n",
    "Jefferson Roylance\n",
    "\n",
    "Justin Fairbourn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this project, we decided to use a dataset of sarcastic and non-sarcastic comments to see if we could classify them correctly using the naive bayes classifier. We combined two ideas - textual analysis of the comment itself, and analysis of the rest of the information about the comment contained in the dataset. In the end, our results were intriguing but we don't feel that it's quite good enough for widespread use. Ideas for further exploration include using k-nearest-neighbors or a neural network in addition to bayes to improve classification ability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset we used was a set of over a million comments, balanced between sarcastic and non-sarcastic. The data was loaded from the .csv file, packaged into an array, and then processed into separate lists containing the data and the labels. The columns of the original dataset are as follows: \n",
    "\n",
    "* label\n",
    "* comment\n",
    "* author\n",
    "* subreddit\n",
    "* score (# of upvotes - # of downvotes)\n",
    "* ups (# of upvotes)\n",
    "* downs (# of downvotes)\n",
    "* date\n",
    "* created_utc\n",
    "* parent_comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis technique\n",
    "\n",
    "For our analysis, we used the multinomial naive bayes classifier, since most of our data was not normally distributed and tests confirmed that using the multinomial classifier was more effective than the gaussian classifier. \n",
    "\n",
    "For the textual analysis of the comment, each comment was converted into a long array containing boolean and number values representing the following characteristics: \n",
    "\n",
    "* Amounts of each letter\n",
    "* Length of the comment (in characters)\n",
    "* Presence of punctuation (boolean)\n",
    "* Average word length\n",
    "* Words used - this was found out by taking the top 500 words used in all comments and then finding the counts of each of those words in the comment\n",
    "* Checking for predefined patterns (we only got around to checking for the presence of '...')\n",
    "* Number of uppercase letters\n",
    "\n",
    "This information was fed into a classifier, which was cross-validated 4 times and scored using the f-score. \n",
    "\n",
    "### Justin analysis\n",
    "\n",
    "In addition to the comments themselves, we wanted to see if we could build a classifier that can detect sarcasm using the subreddit and score data. For memory reasons, we only considered the top 15 subreddits by summing up the frequencies of each subreddit. This gave us a 1,000,000 x 22 DataFrame with \"dummy\" variables that allowed us to represent the categorical subreddit data numerically.\n",
    "\n",
    "Then, we created a Naive-Bayes classifier and fed it the following attributes:\n",
    " * The total amount of \"upvotes\" the comment received.\n",
    " * The total amount of \"downvotes\" the comment received.\n",
    " * 15 dummy boolean variables representing the comment's subreddit.\n",
    " \n",
    "Not satisfied with the f-scores, we also ran another analysis and instead fed the classifier _only_ the subreddit data. Surprisingly, this gave slightly better performance.\n",
    "\n",
    "In both of these analyses, cross-validation was performed 20 times.\n",
    "\n",
    "### Combined analysis\n",
    "\n",
    "Wanting to get the best results possible, we decided to combine the feature sets used in the previous two analyses to create one giant featureset with both the word features and the subreddit features.\n",
    "\n",
    "Unfortunately, this led to some intense memory issues, so we needed to reduce the amount of comments we were analyzing to 10000 in order to successfully fit our 500 features into the Naive-Bayes classifier. Once this was done succesfully, we ran cross-validation 5 times.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Average f-score with only comment textual analysis (using all comments):  0.6209258413787513"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%latex\n",
    "\\newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project X Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments relating to code snippet 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.read_csv(\"data/train-balanced-sarcasm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>date</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NC and NH.</td>\n",
       "      <td>Trumpbart</td>\n",
       "      <td>politics</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>2016-10-16 23:55:23</td>\n",
       "      <td>Yeah, I get that argument. At this point, I'd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "      <td>Shbshb906</td>\n",
       "      <td>nba</td>\n",
       "      <td>-4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-11</td>\n",
       "      <td>2016-11-01 00:24:10</td>\n",
       "      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>They were underdogs earlier today, but since G...</td>\n",
       "      <td>Creepeth</td>\n",
       "      <td>nfl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-09</td>\n",
       "      <td>2016-09-22 21:45:37</td>\n",
       "      <td>They're favored to win.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>This meme isn't funny none of the \"new york ni...</td>\n",
       "      <td>icebrotha</td>\n",
       "      <td>BlackPeopleTwitter</td>\n",
       "      <td>-8</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>2016-10-18 21:03:47</td>\n",
       "      <td>deadass don't kill my buzz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I could use one of those tools.</td>\n",
       "      <td>cush2push</td>\n",
       "      <td>MaddenUltimateTeam</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-12</td>\n",
       "      <td>2016-12-30 17:00:13</td>\n",
       "      <td>Yep can confirm I saw the tool they use for th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            comment     author  \\\n",
       "0      0                                         NC and NH.  Trumpbart   \n",
       "1      0  You do know west teams play against west teams...  Shbshb906   \n",
       "2      0  They were underdogs earlier today, but since G...   Creepeth   \n",
       "3      0  This meme isn't funny none of the \"new york ni...  icebrotha   \n",
       "4      0                    I could use one of those tools.  cush2push   \n",
       "\n",
       "            subreddit  score  ups  downs     date          created_utc  \\\n",
       "0            politics      2   -1     -1  2016-10  2016-10-16 23:55:23   \n",
       "1                 nba     -4   -1     -1  2016-11  2016-11-01 00:24:10   \n",
       "2                 nfl      3    3      0  2016-09  2016-09-22 21:45:37   \n",
       "3  BlackPeopleTwitter     -8   -1     -1  2016-10  2016-10-18 21:03:47   \n",
       "4  MaddenUltimateTeam      6   -1     -1  2016-12  2016-12-30 17:00:13   \n",
       "\n",
       "                                      parent_comment  \n",
       "0  Yeah, I get that argument. At this point, I'd ...  \n",
       "1  The blazers and Mavericks (The wests 5 and 6 s...  \n",
       "2                            They're favored to win.  \n",
       "3                         deadass don't kill my buzz  \n",
       "4  Yep can confirm I saw the tool they use for th...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(comments.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_list = [(\n",
    "    row['label'],\n",
    "    str(row['comment']),\n",
    ") for index, row in comments[:10000].iterrows()]\n",
    "# random.shuffle(comment_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13679"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bigString = ' '.join([comment[1] for comment in comment_list])\n",
    "wordList = re.sub(\"[^\\w]\", \" \",  bigString.lower()).split()\n",
    "\n",
    "bigDict = {}\n",
    "for word in wordList:\n",
    "    if word in bigDict:\n",
    "        bigDict[word] += 1\n",
    "    else:\n",
    "        bigDict[word] = 1\n",
    "display(len(bigDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'a', 'i', 'to', 'you', 'it', 'and', 'that', 'is', 'of']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topWords = sorted(bigDict, key=bigDict.__getitem__, reverse=True)[:500]\n",
    "display(topWords[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "alphabet = 'abcdefghijklmnopqrstuvwxyz1234567890'\n",
    "uppercaseAlphabet = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "punctuation = '*\\\"\\(\\)~:/&\\'.-#[];_^$\\{\\}=!+?@%`,|\\x08'\n",
    "patterns = ['...']\n",
    "alphabet += punctuation\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit([l for l in alphabet])\n",
    "\n",
    "def comment_features_word(comment):\n",
    "    features = []\n",
    "\n",
    "    # Letter counts\n",
    "    for letter in alphabet:\n",
    "        features.append(comment.lower().count(letter))\n",
    "        \n",
    "    # Length\n",
    "    features.append(len(comment))\n",
    "    \n",
    "    # Presence of punctuation\n",
    "    punctPresence = False\n",
    "    for p in punctuation:\n",
    "        punctPresence = punctPresence or p in comment\n",
    "    features.append(punctPresence)\n",
    "    \n",
    "    # Average word length\n",
    "    commentWords = re.sub(\"[^\\w]\", \" \",  comment).split()\n",
    "    a = sum([len(word) for word in commentWords]) / len(commentWords) if len(commentWords) > 0 else 0\n",
    "    features.append(a)\n",
    "    \n",
    "    # Words used\n",
    "    a = []\n",
    "    for word in topWords:\n",
    "        a.append(comment.lower().count(word))\n",
    "    features.extend(a)\n",
    "    \n",
    "    # Checking for predefined patterns\n",
    "    a = []\n",
    "    for pattern in patterns:\n",
    "        a.append(comment.count(pattern))\n",
    "    features.extend(a)\n",
    "    \n",
    "    # Checking for number of uppercase letters\n",
    "    a = 0\n",
    "    for letter in uppercaseAlphabet:\n",
    "        a += comment.count(letter)\n",
    "    features.append(a)\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [comment_features_word(comment) for (_, comment) in comment_list]\n",
    "y = [label for (label, _) in comment_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "\n",
    "cv_results = cross_validate(clf, X, y, cv=4, scoring='f1')\n",
    "\n",
    "print(\"Average f-score: \", sum(cv_results['test_score']) / len(cv_results['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Subreddit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    183069\n",
       "0    169832\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subreddit_counts = comments['subreddit'].value_counts()\n",
    "comments_counts = comments.join(subreddit_counts, on='subreddit', rsuffix='_count')\n",
    "comments_counts = comments_counts[comments_counts.subreddit_count > 8000]\n",
    "subreddit_data = pd.get_dummies(comments_counts['subreddit'], prefix='r',sparse=True)\n",
    "display(comments_counts['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45120739203004334"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6313335178541213"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Drop everything except for the subreddit dummy values and the up/down scores and the labels\n",
    "comments_test = comments_counts.drop(['comment', 'subreddit', 'author', 'date', 'created_utc', 'parent_comment','score','subreddit_count'], axis=1)\n",
    "dummy_comments = pd.concat([comments_test, subreddit_data], axis=1)\n",
    "\n",
    "# Take absolute value of each score since NBC's don't like negative numbers\n",
    "dummy_comments['ups'] = abs(dummy_comments['ups'])\n",
    "dummy_comments['downs'] = abs(dummy_comments['downs'])\n",
    "\n",
    "X = dummy_comments.drop('label', axis=1).values\n",
    "y = dummy_comments['label'].values\n",
    "\n",
    "f_scores_0 = []\n",
    "f_scores_1 = []\n",
    "\n",
    "for _ in range(20):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    p,r,f,s = precision_recall_fscore_support(y_test, y_pred)\n",
    "    \n",
    "    f_scores_0.append(f[0])\n",
    "    f_scores_1.append(f[1])\n",
    "\n",
    "display(sum(f_scores_0) / float(len(f_scores_0)))\n",
    "display(sum(f_scores_1) / float(len(f_scores_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5120295077828744"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6111735985429384"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Drop everything except for the subreddit dummy values and the labels\n",
    "comments_test_no_scores = comments_counts.drop(['comment', 'subreddit', 'author', 'date', 'created_utc', 'parent_comment','score','subreddit_count','ups','downs'], axis=1)\n",
    "dummy_comments_no_scores = pd.concat([comments_test_no_scores, subreddit_data], axis=1)\n",
    "\n",
    "X = dummy_comments_no_scores.drop('label', axis=1).values\n",
    "y = dummy_comments_no_scores['label'].values\n",
    "\n",
    "f_scores_0_no_scores = []\n",
    "f_scores_1_no_scores = []\n",
    "\n",
    "for _ in range(20):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    p,r,f,s = precision_recall_fscore_support(y_test, y_pred)\n",
    "    \n",
    "    f_scores_0_no_scores.append(f[0])\n",
    "    f_scores_1_no_scores.append(f[1])\n",
    "    \n",
    "display(sum(f_scores_0_no_scores) / float(len(f_scores_0_no_scores)))\n",
    "display(sum(f_scores_1_no_scores) / float(len(f_scores_1_no_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The f-scores for the data _without_ the scores was slightly better, we'll combine those features with the comment word features to do our final analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Drop everything except for the subreddit dummy values and the labels\n",
    "comments_test_full = comments_counts[:1000]\n",
    "comments_test_full = comments_test_full.drop(['subreddit', 'author', 'date', 'created_utc', 'parent_comment','score','subreddit_count','ups','downs'], axis=1)\n",
    "comments_test_full = pd.concat([comments_test_full, subreddit_data], axis=1)\n",
    "\n",
    "X = comments_test_full.drop(['label','comment'], axis=1).values.tolist()\n",
    "y = comments_test_full['label'].values.tolist()\n",
    "comments = comments_test_full['comment'].values.tolist()\n",
    "\n",
    "for i in range(len(X)):\n",
    "    next_comment = str(comments[i])\n",
    "    X[i].extend(comment_features_word(next_comment))\n",
    "\n",
    "\n",
    "comments_test_full = []\n",
    "\n",
    "print('finished extending')\n",
    "f_scores_0_no_scores = []\n",
    "f_scores_1_no_scores = []\n",
    "\n",
    "for i in range(20):\n",
    "    print(i)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    p,r,f,s = precision_recall_fscore_support(y_test, y_pred)\n",
    "    \n",
    "    f_scores_0_no_scores.append(f[0])\n",
    "    f_scores_1_no_scores.append(f[1])\n",
    "    \n",
    "display(sum(f_scores_0_no_scores) / float(len(f_scores_0_no_scores)))\n",
    "display(sum(f_scores_1_no_scores) / float(len(f_scores_1_no_scores)))\n",
    "                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = None\n",
    "y = None\n",
    "comments_test_full = None\n",
    "X_train = None\n",
    "y_train = None\n",
    "X_test = None\n",
    "y_test = None\n",
    "clf = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
