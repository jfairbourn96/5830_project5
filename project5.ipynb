{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 5 Report\n",
    "\n",
    "## Team members: \n",
    "\n",
    "Jefferson Roylance\n",
    "\n",
    "Justin Fairbourn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this project, we decided to use a dataset of sarcastic and non-sarcastic comments to see if we could classify them correctly using the naive bayes classifier. We combined two ideas - textual analysis of the comment itself, and analysis of the rest of the information about the comment contained in the dataset. In the end, our results were intriguing but we don't feel that it's quite good enough for widespread use. Ideas for further exploration include using k-nearest-neighbors or a neural network in addition to bayes to improve classification ability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset we used was a set of over a million comments, balanced between sarcastic and non-sarcastic. The data was loaded from the .csv file, packaged into an array, and then processed into separate lists containing the data and the labels. The columns of the original dataset are as follows: \n",
    "\n",
    "* label\n",
    "* comment\n",
    "* author\n",
    "* subreddit\n",
    "* score (# of upvotes - # of downvotes)\n",
    "* ups (# of upvotes)\n",
    "* downs (# of downvotes)\n",
    "* date\n",
    "* created_utc\n",
    "* parent_comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis technique\n",
    "\n",
    "For our analysis, we used the multinomial naive bayes classifier, since most of our data was not normally distributed and tests confirmed that using the multinomial classifier was more effective than the gaussian classifier. \n",
    "\n",
    "For the textual analysis of the comment, each comment was converted into a long array containing boolean and number values representing the following characteristics: \n",
    "\n",
    "* Amounts of each letter\n",
    "* Length of the comment (in characters)\n",
    "* Presence of punctuation (boolean)\n",
    "* Average word length\n",
    "* Words used - this was found out by taking the top 500 words used in all comments and then finding the counts of each of those words in the comment\n",
    "* Checking for predefined patterns (we only got around to checking for the presence of '...')\n",
    "* Number of uppercase letters\n",
    "\n",
    "This information was fed into a classifier, which was cross-validated 4 times and scored using the f-score. \n",
    "\n",
    "### Justin analysis\n",
    "\n",
    "### Combined analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Using the classifier to judge comments solely based on our analysis of the comment itself, we got the following result: \n",
    "Average f-score with only comment textual analysis (using all comments):  0.6209258413787513\n",
    "\n",
    "\n",
    "The most fascinating part of this system is how it could be potentially used. If accuracy was extremely high, for example, reddit could go through and tag all sarcastic comments to stop people from misunderstanding. This could also be used in messaging apps if the classifier thinks that a message is sarcastic. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%latex\n",
    "\\newpage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project X Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments relating to code snippet 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.read_csv(\"train-balanced-sarcasm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>date</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NC and NH.</td>\n",
       "      <td>Trumpbart</td>\n",
       "      <td>politics</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>2016-10-16 23:55:23</td>\n",
       "      <td>Yeah, I get that argument. At this point, I'd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "      <td>Shbshb906</td>\n",
       "      <td>nba</td>\n",
       "      <td>-4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-11</td>\n",
       "      <td>2016-11-01 00:24:10</td>\n",
       "      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>They were underdogs earlier today, but since G...</td>\n",
       "      <td>Creepeth</td>\n",
       "      <td>nfl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-09</td>\n",
       "      <td>2016-09-22 21:45:37</td>\n",
       "      <td>They're favored to win.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>This meme isn't funny none of the \"new york ni...</td>\n",
       "      <td>icebrotha</td>\n",
       "      <td>BlackPeopleTwitter</td>\n",
       "      <td>-8</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>2016-10-18 21:03:47</td>\n",
       "      <td>deadass don't kill my buzz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I could use one of those tools.</td>\n",
       "      <td>cush2push</td>\n",
       "      <td>MaddenUltimateTeam</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-12</td>\n",
       "      <td>2016-12-30 17:00:13</td>\n",
       "      <td>Yep can confirm I saw the tool they use for th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            comment     author  \\\n",
       "0      0                                         NC and NH.  Trumpbart   \n",
       "1      0  You do know west teams play against west teams...  Shbshb906   \n",
       "2      0  They were underdogs earlier today, but since G...   Creepeth   \n",
       "3      0  This meme isn't funny none of the \"new york ni...  icebrotha   \n",
       "4      0                    I could use one of those tools.  cush2push   \n",
       "\n",
       "            subreddit  score  ups  downs     date          created_utc  \\\n",
       "0            politics      2   -1     -1  2016-10  2016-10-16 23:55:23   \n",
       "1                 nba     -4   -1     -1  2016-11  2016-11-01 00:24:10   \n",
       "2                 nfl      3    3      0  2016-09  2016-09-22 21:45:37   \n",
       "3  BlackPeopleTwitter     -8   -1     -1  2016-10  2016-10-18 21:03:47   \n",
       "4  MaddenUltimateTeam      6   -1     -1  2016-12  2016-12-30 17:00:13   \n",
       "\n",
       "                                      parent_comment  \n",
       "0  Yeah, I get that argument. At this point, I'd ...  \n",
       "1  The blazers and Mavericks (The wests 5 and 6 s...  \n",
       "2                            They're favored to win.  \n",
       "3                         deadass don't kill my buzz  \n",
       "4  Yep can confirm I saw the tool they use for th...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(comments.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_list = [(\n",
    "    row['label'],\n",
    "    str(row['comment']),\n",
    ") for index, row in comments.iterrows()]\n",
    "random.shuffle(comment_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_list_truncated = comment_list[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167472"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bigString = ' '.join([comment[1] for comment in comment_list])\n",
    "wordList = re.sub(\"[^\\w]\", \" \",  bigString.lower()).split()\n",
    "\n",
    "bigDict = {}\n",
    "for word in wordList:\n",
    "    if word in bigDict:\n",
    "        bigDict[word] += 1\n",
    "    else:\n",
    "        bigDict[word] = 1\n",
    "display(len(bigDict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'a', 'to', 'i', 'you', 'it', 'and', 'that', 'is', 'of']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topWords = sorted(bigDict, key=bigDict.__getitem__, reverse=True)[:500]\n",
    "display(topWords[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "alphabet = 'abcdefghijklmnopqrstuvwxyz1234567890'\n",
    "uppercaseAlphabet = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "punctuation = '*\\\"\\(\\)~:/&\\'.-#[];_^$\\{\\}=!+?@%`,|\\x08'\n",
    "patterns = ['...']\n",
    "alphabet += punctuation\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit([l for l in alphabet])\n",
    "\n",
    "def comment_features_word(comment):\n",
    "    features = []\n",
    "\n",
    "    # Letter counts\n",
    "    for letter in alphabet:\n",
    "        features.append(comment.lower().count(letter))\n",
    "        \n",
    "    # Length\n",
    "    features.append(len(comment))\n",
    "    \n",
    "    # Presence of punctuation\n",
    "    punctPresence = False\n",
    "    for p in punctuation:\n",
    "        punctPresence = punctPresence or p in comment\n",
    "    features.append(punctPresence)\n",
    "    \n",
    "    # Average word length\n",
    "    commentWords = re.sub(\"[^\\w]\", \" \",  comment).split()\n",
    "    a = sum([len(word) for word in commentWords]) / len(commentWords) if len(commentWords) > 0 else 0\n",
    "    features.append(a)\n",
    "    \n",
    "    # Words used\n",
    "    a = []\n",
    "    for word in topWords:\n",
    "        a.append(comment.lower().count(word))\n",
    "    features.extend(a)\n",
    "    \n",
    "    # Checking for predefined patterns\n",
    "    a = []\n",
    "    for pattern in patterns:\n",
    "        a.append(comment.count(pattern))\n",
    "    features.extend(a)\n",
    "    \n",
    "    # Checking for number of uppercase letters\n",
    "    a = 0\n",
    "    for letter in uppercaseAlphabet:\n",
    "        a += comment.count(letter)\n",
    "    features.append(a)\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [comment_features_word(comment) for (_, comment) in comment_list_truncated]\n",
    "y = [label for (label, _) in comment_list_truncated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average f-score:  0.6425650674933281\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "\n",
    "cv_results = cross_validate(clf, X, y, cv=4, scoring='f1')\n",
    "\n",
    "print(\"Average f-score: \", sum(cv_results['test_score']) / len(cv_results['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
